{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1ab568",
   "metadata": {},
   "source": [
    "# アンドロイドは「青信号」の夢を見るか？\n",
    "\n",
    "## 概要\n",
    "\n",
    "- **背景:** 日本語の「青」は、物理的な緑色スペクトルの一部（信号機、野菜など）を包含する性質を持つ\n",
    "- **RQ:** 言語データで学習されたVision-Language Models (VLMs) は、この言語的なねじれ（サピア・ウォーフ効果）を視覚認識において再現するか？すなわち、**日本語特化モデルは英語モデルに比べて、「緑色」を「青」と判定する確率が高いか？**\n",
    "- **アプローチ:** CIELAB色空間上で制御された画像に対するモデルの応答曲線を計測\n",
    "\n",
    "## 実験設定\n",
    "\n",
    "### タスク定義とデータセット構築\n",
    "\n",
    "- CIELAB色空間上で制御された、2種類の画像 (タスク) に対するモデルの応答曲線を計測\n",
    "  1. 脱文脈化された色彩 (Decontextualized Color Patches)\n",
    "  2. 文脈化された色彩 (Contextualized Objects)\n",
    "- 各プロンプトテンプレートの埋め込みベクトルと画像埋め込みのコサイン類似度を計算し、Softmax関数で確率化\n",
    "- 複数プロンプトの場合は平均を取る\n",
    "\n",
    "#### タスク1: 脱文脈化された色彩 (Decontextualized Color Patches)\n",
    "\n",
    "知覚的な均等性を保つため、RGB/HSVではなく **CIELAB ($L^*C^*h$) 色空間** を使用\n",
    "\n",
    "- 明度 ($L^*$) と 彩度 ($C^*$) を固定し、色相角 ($h$) のみを変化させた単色パッチ。\n",
    "- **Range:** $h \\in [120^\\circ, 240^\\circ]$ (Green $\\to$ Blue)\n",
    "- **Step:** $1^\\circ$ 刻み (計121枚)\n",
    "- **Fixed Values:** $L^*=60, C^*=50$ (典型的な表示デバイスで再現可能な範囲)\n",
    "- **Size:** $256 \\times 256$ px\n",
    "\n",
    "#### タスク2: 文脈化された色彩 (Contextualized Objects)\n",
    "\n",
    "- 交通信号機 (Traffic Light) の画像における「点灯部分」のみをマスクし、上記と同様に色相回転 (Hue Shift) を適用する。\n",
    "- これにより、「信号機」という物体認識が色彩判定に与えるバイアス (Top-down effect) を検証する。\n",
    "- **枚数**: 1210 枚\n",
    "  - $10$ 種類の信号画像それぞれに対して $1^\\circ$ 刻み（計 $121$ 枚）の色相回転を適用\n",
    "\n",
    "### モデル選定\n",
    "\n",
    "#### 選定基準\n",
    "\n",
    "- 公平な比較を期するため、なるべく同じベースモデル・パラメータサイズ、パッチサイズのモデルを使用\n",
    "\n",
    "#### 選定モデル\n",
    "\n",
    "| カテゴリ | モデルID (Hugging Face) |\n",
    "| :--- | :--- |\n",
    "| **English Native** | `openai/clip-vit-large-patch14` |\n",
    "| **Japanese Native** | `llm-jp/llm-jp-clip-vit-large-patch14` |\n",
    "| **Multilingual** | `sentence-transformers/clip-ViT-B-32-multilingual-v1` |\n",
    "\n",
    "### プロンプトエンジニアリング\n",
    "\n",
    "単一プロンプトのノイズを低減するため、**Prompt Ensembling** を採用する。複数のテンプレートの平均埋め込みベクトルを使用する。\n",
    "\n",
    "- **英語 (En):**\n",
    "  - `\"a photo of a {color} color\"`\n",
    "  - `\"a {color} patch\"`\n",
    "  - `\"the color is {color}\"`\n",
    "  - `\"this is {color}\"`\n",
    "  \n",
    "- **日本語 (Ja):**\n",
    "  - `\"{色}の色の写真\"`\n",
    "  - `\"{色}のパッチ\"`\n",
    "  - `\"色は{色}です\"`\n",
    "  - `\"これは{色}です\"`\n",
    "\n",
    "- **ターゲットラベル:**\n",
    "  - En: `Blue` vs `Green`\n",
    "  - Ja: `青` vs `緑`\n",
    "\n",
    "### 評価指標\n",
    "\n",
    "各色相角 $h_i$ における「青/Ao」の予測確率 $P(\\text{Blue}|h_i)$ を算出し、以下の指標を計算する。\n",
    "\n",
    "#### 1. Point of Subjective Equality (PSE: 主観的等価点)\n",
    "\n",
    "「青」と「緑」の確率が等しくなる色相角。\n",
    "$$\n",
    "PSE = \\{ h \\mid P(\\text{Blue}|h) = 0.5 \\}\n",
    "$$\n",
    "※ 日本語モデルのPSEは、英語モデルよりも緑側（小さい角度）にシフトしていると仮定される。\n",
    "\n",
    "#### 2. Cultural Color Shift ($\\Delta PSE$)\n",
    "\n",
    "英語モデルと日本語モデルの境界線のズレ。\n",
    "$$\n",
    "\\Delta PSE = PSE_{Ja} - PSE_{En}\n",
    "$$\n",
    "\n",
    "#### 3. JND (Just Noticeable Difference) 近似 / Transition Width\n",
    "\n",
    "確率が25%から75%に変化する色相の幅。境界の「曖昧さ」を表す。\n",
    "\n",
    "## 実験結果\n",
    "\n",
    "※ この表の数値を埋めていく\n",
    "\n",
    "| 実験設定 | モデル | プロンプト | P(Blue\\|h) |\n",
    "|:--------:|:-------|:-----------|-----:|\n",
    "| 1        | en     | en         |  |\n",
    "| 1        | ja     | ja         |  |\n",
    "| 1        | mul    | en         |  |\n",
    "| 1        | mul    | ja         |  |\n",
    "| 2        | en     | en         |  |\n",
    "| 2        | ja     | ja         |  |\n",
    "| 2        | mul    | en         |  |\n",
    "| 2        | mul    | ja         |  |\n",
    "\n",
    "## 参考\n",
    "\n",
    "- 似た疑問があった: [How are boundaries between colors defined? Are they a cultural/linguistic/anthropological phenomenon stricto sensu, or are there biological/neurological bases behind color definition? : r/askscience](https://www.reddit.com/r/askscience/comments/vx4mql/how_are_boundaries_between_colors_defined_are/)\n",
    "\n",
    "## その他補足やメモなど\n",
    "\n",
    "### 初期アイデア\n",
    "\n",
    "- **素朴な疑問:** 日本では緑色の信号を「青」と言います。また、「青菜」「青虫」も緑色です。**AI（CLIPなど）の視覚と言語の境界**において、「青」という言葉がカバーする「緑色の領域」はどこまで広いのか？\n",
    "- **技術的アプローチ:**\n",
    "    - **手法:** 色相環（カラーピッカー）で、「完全な青」から少しずつ「完全な緑」へ色を変化させた画像を用意する。\n",
    "    - **判定:** 画像認識AI（CLIP）に画像を見せ、「これは『青』ですか？『緑』ですか？」という確率（Softmax）を出させる。\n",
    "    - **比較:** 日本語モデルと英語モデル（Blue vs Green）で比較し、**日本語モデルだけが「緑色なのに青と言い張る領域（文化的な歪み）」**を可視化する。\n",
    "    - **面白ポイント:** 言語が色の認識を歪めている様子を、数学的に可視化できます。「日本語AIは、このくらい緑でも『青だ』と言い張ります」という結果は知的好奇心をくすぐります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f3717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 12 05:54:15 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   45C    P8             11W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe6ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験1用の画像を生成\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
